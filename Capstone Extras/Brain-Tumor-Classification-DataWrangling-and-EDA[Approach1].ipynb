{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling and EDA (Brain Tumor Classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os, sys\n",
    "import cv2\n",
    "import PIL\n",
    "import os.path\n",
    "from PIL import Image, ImageOps\n",
    "import scipy.ndimage as ndi\n",
    "from skimage import color\n",
    "from skimage.filters import gaussian\n",
    "from tqdm import tqdm\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from tensorflow.keras.applications import MobileNet, MobileNetV2, VGG16\n",
    "# from tensorflow.keras.applications.mobilenet import MobileNet\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Dropout, Dense, BatchNormalization, Flatten\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tqdm import tqdm\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../BrainMRI\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Testing', 'Training', 'Validation']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(os.listdir(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Glioma', 'Meningioma', 'NoTumor', 'Pituitary']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(os.listdir(path + \"/Training\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Glioma', 'Meningioma', 'NoTumor', 'Pituitary']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(os.listdir(path + \"/Testing\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['Glioma','NoTumor','Meningioma','Pituitary']\n",
    "\n",
    "class_map = {\n",
    "    'NoTumor': 0,\n",
    "    'Glioma': 1,\n",
    "    'Meningioma': 2,\n",
    "    'Pituitary': 3\n",
    "}\n",
    "\n",
    "inverse_class_map = {\n",
    "    0: 'NoTumor',\n",
    "    1: 'Glioma',\n",
    "    2: 'Meningioma',\n",
    "    3: 'Pituitary'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "h, w = 300, 300\n",
    "batch_size = 96\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 310/310 [00:00<00:00, 351.43it/s]\n",
      "100%|██████████| 150/150 [00:00<00:00, 383.59it/s]\n",
      "100%|██████████| 308/308 [00:00<00:00, 365.62it/s]\n",
      "100%|██████████| 310/310 [00:01<00:00, 298.98it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 360.45it/s]\n",
      "100%|██████████| 105/105 [00:00<00:00, 702.28it/s]\n",
      "100%|██████████| 115/115 [00:00<00:00, 442.82it/s]\n",
      "100%|██████████| 74/74 [00:00<00:00, 189.23it/s]\n"
     ]
    }
   ],
   "source": [
    "IMAGE = []\n",
    "LABELS = []\n",
    "\n",
    "for label in labels:\n",
    "    folderPath = os.path.join('../BrainMRI/Training', label)\n",
    "    for j in tqdm(os.listdir(folderPath)):\n",
    "        img = cv2.imread(os.path.join(folderPath, j))\n",
    "        img = cv2.resize(img,(h, w))\n",
    "        IMAGE.append(img)\n",
    "        LABELS.append(class_map[label])\n",
    "            \n",
    "        \n",
    "for label in labels:\n",
    "    folderPath = os.path.join('../BrainMRI/Testing', label)\n",
    "    for j in tqdm(os.listdir(folderPath)):\n",
    "        img = cv2.imread(os.path.join(folderPath,j))\n",
    "        img = cv2.resize(img,(h, w))\n",
    "        IMAGE.append(img)\n",
    "        LABELS.append(class_map[label])\n",
    "        \n",
    "X = np.array(IMAGE)\n",
    "y = np.array(LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = shuffle(X, y, random_state=42)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, to_categorical(y), test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the Simple model using Dense Layer [optimizer = 'adam']\n",
    "early_stopping_monitor = EarlyStopping(patience=3)\n",
    "model1 = Sequential()\n",
    "model1.add(Flatten(input_shape=(300,300,1)))\n",
    "model1.add(Dense(512, activation='relu'))\n",
    "model1.add(Dense(256, activation='relu'))\n",
    "model1.add(Dense(128, activation='relu'))\n",
    "model1.add(Dense(64, activation='relu'))\n",
    "model1.add(Dense(32, activation='relu'))\n",
    "model1.add(Dense(16, activation='relu'))\n",
    "model1.add(Dense(4, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model1.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-28-11391772b02b>:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history11 = model1.fit_generator(datagen.flow(X_train, y_train, batch_size = batch_size), validation_data = (X_test, y_test),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": " logits and labels must be broadcastable: logits_size=[288,4] labels_size=[96,4]\n\t [[node categorical_crossentropy/softmax_cross_entropy_with_logits\n (defined at C:\\Users\\shaja\\Anaconda3\\lib\\site-packages\\keras\\backend.py:5009)\n]] [Op:__inference_train_function_2667]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node categorical_crossentropy/softmax_cross_entropy_with_logits:\nIn[0] categorical_crossentropy/softmax_cross_entropy_with_logits/Reshape:\t\nIn[1] categorical_crossentropy/softmax_cross_entropy_with_logits/Reshape_1:\n\nOperation defined at: (most recent call last)\n>>>   File \"C:\\Users\\shaja\\Anaconda3\\lib\\runpy.py\", line 194, in _run_module_as_main\n>>>     return _run_code(code, main_globals, None,\n>>> \n>>>   File \"C:\\Users\\shaja\\Anaconda3\\lib\\runpy.py\", line 87, in _run_code\n>>>     exec(code, run_globals)\n>>> \n>>>   File \"C:\\Users\\shaja\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n>>>     app.launch_new_instance()\n>>> \n>>>   File \"C:\\Users\\shaja\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 845, in launch_instance\n>>>     app.start()\n>>> \n>>>   File \"C:\\Users\\shaja\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 612, in start\n>>>     self.io_loop.start()\n>>> \n>>>   File \"C:\\Users\\shaja\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 149, in start\n>>>     self.asyncio_loop.run_forever()\n>>> \n>>>   File \"C:\\Users\\shaja\\Anaconda3\\lib\\asyncio\\base_events.py\", line 570, in run_forever\n>>>     self._run_once()\n>>> \n>>>   File \"C:\\Users\\shaja\\Anaconda3\\lib\\asyncio\\base_events.py\", line 1859, in _run_once\n>>>     handle._run()\n>>> \n>>>   File \"C:\\Users\\shaja\\Anaconda3\\lib\\asyncio\\events.py\", line 81, in _run\n>>>     self._context.run(self._callback, *self._args)\n>>> \n>>>   File \"C:\\Users\\shaja\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 690, in <lambda>\n>>>     lambda f: self._run_callback(functools.partial(callback, future))\n>>> \n>>>   File \"C:\\Users\\shaja\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 743, in _run_callback\n>>>     ret = callback()\n>>> \n>>>   File \"C:\\Users\\shaja\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 787, in inner\n>>>     self.run()\n>>> \n>>>   File \"C:\\Users\\shaja\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 748, in run\n>>>     yielded = self.gen.send(value)\n>>> \n>>>   File \"C:\\Users\\shaja\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 365, in process_one\n>>>     yield gen.maybe_future(dispatch(*args))\n>>> \n>>>   File \"C:\\Users\\shaja\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n>>>     yielded = next(result)\n>>> \n>>>   File \"C:\\Users\\shaja\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 268, in dispatch_shell\n>>>     yield gen.maybe_future(handler(stream, idents, msg))\n>>> \n>>>   File \"C:\\Users\\shaja\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n>>>     yielded = next(result)\n>>> \n>>>   File \"C:\\Users\\shaja\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 543, in execute_request\n>>>     self.do_execute(\n>>> \n>>>   File \"C:\\Users\\shaja\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n>>>     yielded = next(result)\n>>> \n>>>   File \"C:\\Users\\shaja\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 306, in do_execute\n>>>     res = shell.run_cell(code, store_history=store_history, silent=silent)\n>>> \n>>>   File \"C:\\Users\\shaja\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n>>>     return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\shaja\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2877, in run_cell\n>>>     result = self._run_cell(\n>>> \n>>>   File \"C:\\Users\\shaja\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2923, in _run_cell\n>>>     return runner(coro)\n>>> \n>>>   File \"C:\\Users\\shaja\\Anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n>>>     coro.send(None)\n>>> \n>>>   File \"C:\\Users\\shaja\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3146, in run_cell_async\n>>>     has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n>>> \n>>>   File \"C:\\Users\\shaja\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3338, in run_ast_nodes\n>>>     if (await self.run_code(code, result,  async_=asy)):\n>>> \n>>>   File \"C:\\Users\\shaja\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3418, in run_code\n>>>     exec(code_obj, self.user_global_ns, self.user_ns)\n>>> \n>>>   File \"<ipython-input-28-11391772b02b>\", line 1, in <module>\n>>>     history11 = model1.fit_generator(datagen.flow(X_train, y_train, batch_size = batch_size), validation_data = (X_test, y_test),\n>>> \n>>>   File \"C:\\Users\\shaja\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 2016, in fit_generator\n>>>     return self.fit(\n>>> \n>>>   File \"C:\\Users\\shaja\\Anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\shaja\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1216, in fit\n>>>     tmp_logs = self.train_function(iterator)\n>>> \n>>>   File \"C:\\Users\\shaja\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 878, in train_function\n>>>     return step_function(self, iterator)\n>>> \n>>>   File \"C:\\Users\\shaja\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 867, in step_function\n>>>     outputs = model.distribute_strategy.run(run_step, args=(data,))\n>>> \n>>>   File \"C:\\Users\\shaja\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 860, in run_step\n>>>     outputs = model.train_step(data)\n>>> \n>>>   File \"C:\\Users\\shaja\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 809, in train_step\n>>>     loss = self.compiled_loss(\n>>> \n>>>   File \"C:\\Users\\shaja\\Anaconda3\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 201, in __call__\n>>>     loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n>>> \n>>>   File \"C:\\Users\\shaja\\Anaconda3\\lib\\site-packages\\keras\\losses.py\", line 141, in __call__\n>>>     losses = call_fn(y_true, y_pred)\n>>> \n>>>   File \"C:\\Users\\shaja\\Anaconda3\\lib\\site-packages\\keras\\losses.py\", line 245, in call\n>>>     return ag_fn(y_true, y_pred, **self._fn_kwargs)\n>>> \n>>>   File \"C:\\Users\\shaja\\Anaconda3\\lib\\site-packages\\keras\\losses.py\", line 1664, in categorical_crossentropy\n>>>     return backend.categorical_crossentropy(\n>>> \n>>>   File \"C:\\Users\\shaja\\Anaconda3\\lib\\site-packages\\keras\\backend.py\", line 5009, in categorical_crossentropy\n>>>     return tf.nn.softmax_cross_entropy_with_logits(\n>>> ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-11391772b02b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m history11 = model1.fit_generator(datagen.flow(X_train, y_train, batch_size = batch_size), validation_data = (X_test, y_test),\n\u001b[0m\u001b[0;32m      2\u001b[0m                     steps_per_epoch = len(X_train) / batch_size, epochs = epochs, callbacks = [early_stopping_monitor])\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   2014\u001b[0m         \u001b[1;34m'Please use `Model.fit`, which supports generators.'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2015\u001b[0m         stacklevel=2)\n\u001b[1;32m-> 2016\u001b[1;33m     return self.fit(\n\u001b[0m\u001b[0;32m   2017\u001b[0m         \u001b[0mgenerator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2018\u001b[0m         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     59\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     60\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m:  logits and labels must be broadcastable: logits_size=[288,4] labels_size=[96,4]\n\t [[node categorical_crossentropy/softmax_cross_entropy_with_logits\n (defined at C:\\Users\\shaja\\Anaconda3\\lib\\site-packages\\keras\\backend.py:5009)\n]] [Op:__inference_train_function_2667]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node categorical_crossentropy/softmax_cross_entropy_with_logits:\nIn[0] categorical_crossentropy/softmax_cross_entropy_with_logits/Reshape:\t\nIn[1] categorical_crossentropy/softmax_cross_entropy_with_logits/Reshape_1:\n\nOperation defined at: (most recent call last)\n>>>   File \"C:\\Users\\shaja\\Anaconda3\\lib\\runpy.py\", line 194, in _run_module_as_main\n>>>     return _run_code(code, main_globals, None,\n>>> \n>>>   File \"C:\\Users\\shaja\\Anaconda3\\lib\\runpy.py\", line 87, in _run_code\n>>>     exec(code, run_globals)\n>>> \n>>>   File \"C:\\Users\\shaja\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n>>>     app.launch_new_instance()\n>>> \n>>>   File \"C:\\Users\\shaja\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 845, in launch_instance\n>>>     app.start()\n>>> \n>>>   File \"C:\\Users\\shaja\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 612, in start\n>>>     self.io_loop.start()\n>>> \n>>>   File \"C:\\Users\\shaja\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 149, in start\n>>>     self.asyncio_loop.run_forever()\n>>> \n>>>   File \"C:\\Users\\shaja\\Anaconda3\\lib\\asyncio\\base_events.py\", line 570, in run_forever\n>>>     self._run_once()\n>>> \n>>>   File \"C:\\Users\\shaja\\Anaconda3\\lib\\asyncio\\base_events.py\", line 1859, in _run_once\n>>>     handle._run()\n>>> \n>>>   File \"C:\\Users\\shaja\\Anaconda3\\lib\\asyncio\\events.py\", line 81, in _run\n>>>     self._context.run(self._callback, *self._args)\n>>> \n>>>   File \"C:\\Users\\shaja\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 690, in <lambda>\n>>>     lambda f: self._run_callback(functools.partial(callback, future))\n>>> \n>>>   File \"C:\\Users\\shaja\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 743, in _run_callback\n>>>     ret = callback()\n>>> \n>>>   File \"C:\\Users\\shaja\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 787, in inner\n>>>     self.run()\n>>> \n>>>   File \"C:\\Users\\shaja\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 748, in run\n>>>     yielded = self.gen.send(value)\n>>> \n>>>   File \"C:\\Users\\shaja\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 365, in process_one\n>>>     yield gen.maybe_future(dispatch(*args))\n>>> \n>>>   File \"C:\\Users\\shaja\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n>>>     yielded = next(result)\n>>> \n>>>   File \"C:\\Users\\shaja\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 268, in dispatch_shell\n>>>     yield gen.maybe_future(handler(stream, idents, msg))\n>>> \n>>>   File \"C:\\Users\\shaja\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n>>>     yielded = next(result)\n>>> \n>>>   File \"C:\\Users\\shaja\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 543, in execute_request\n>>>     self.do_execute(\n>>> \n>>>   File \"C:\\Users\\shaja\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n>>>     yielded = next(result)\n>>> \n>>>   File \"C:\\Users\\shaja\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 306, in do_execute\n>>>     res = shell.run_cell(code, store_history=store_history, silent=silent)\n>>> \n>>>   File \"C:\\Users\\shaja\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n>>>     return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\shaja\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2877, in run_cell\n>>>     result = self._run_cell(\n>>> \n>>>   File \"C:\\Users\\shaja\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2923, in _run_cell\n>>>     return runner(coro)\n>>> \n>>>   File \"C:\\Users\\shaja\\Anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n>>>     coro.send(None)\n>>> \n>>>   File \"C:\\Users\\shaja\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3146, in run_cell_async\n>>>     has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n>>> \n>>>   File \"C:\\Users\\shaja\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3338, in run_ast_nodes\n>>>     if (await self.run_code(code, result,  async_=asy)):\n>>> \n>>>   File \"C:\\Users\\shaja\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3418, in run_code\n>>>     exec(code_obj, self.user_global_ns, self.user_ns)\n>>> \n>>>   File \"<ipython-input-28-11391772b02b>\", line 1, in <module>\n>>>     history11 = model1.fit_generator(datagen.flow(X_train, y_train, batch_size = batch_size), validation_data = (X_test, y_test),\n>>> \n>>>   File \"C:\\Users\\shaja\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 2016, in fit_generator\n>>>     return self.fit(\n>>> \n>>>   File \"C:\\Users\\shaja\\Anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\shaja\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1216, in fit\n>>>     tmp_logs = self.train_function(iterator)\n>>> \n>>>   File \"C:\\Users\\shaja\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 878, in train_function\n>>>     return step_function(self, iterator)\n>>> \n>>>   File \"C:\\Users\\shaja\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 867, in step_function\n>>>     outputs = model.distribute_strategy.run(run_step, args=(data,))\n>>> \n>>>   File \"C:\\Users\\shaja\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 860, in run_step\n>>>     outputs = model.train_step(data)\n>>> \n>>>   File \"C:\\Users\\shaja\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 809, in train_step\n>>>     loss = self.compiled_loss(\n>>> \n>>>   File \"C:\\Users\\shaja\\Anaconda3\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 201, in __call__\n>>>     loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n>>> \n>>>   File \"C:\\Users\\shaja\\Anaconda3\\lib\\site-packages\\keras\\losses.py\", line 141, in __call__\n>>>     losses = call_fn(y_true, y_pred)\n>>> \n>>>   File \"C:\\Users\\shaja\\Anaconda3\\lib\\site-packages\\keras\\losses.py\", line 245, in call\n>>>     return ag_fn(y_true, y_pred, **self._fn_kwargs)\n>>> \n>>>   File \"C:\\Users\\shaja\\Anaconda3\\lib\\site-packages\\keras\\losses.py\", line 1664, in categorical_crossentropy\n>>>     return backend.categorical_crossentropy(\n>>> \n>>>   File \"C:\\Users\\shaja\\Anaconda3\\lib\\site-packages\\keras\\backend.py\", line 5009, in categorical_crossentropy\n>>>     return tf.nn.softmax_cross_entropy_with_logits(\n>>> "
     ]
    }
   ],
   "source": [
    "\n",
    "history11 = model1.fit_generator(datagen.flow(X_train, y_train, batch_size = batch_size), validation_data = (X_test, y_test),\n",
    "                    steps_per_epoch = len(X_train) / batch_size, epochs = epochs, callbacks = [early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specifying Model Architecture (Convolutional Neural Network)\n",
    "early_stopping_monitor = EarlyStopping(patience=3)\n",
    "\n",
    "model2 = keras.Sequential()\n",
    "\n",
    "# Convolutional layer and maxpool layer 1\n",
    "model2.add(keras.layers.Conv2D(32,(3,3),activation='relu',input_shape=(300,300,1)))\n",
    "model2.add(keras.layers.MaxPool2D(2,2))\n",
    "\n",
    "# Convolutional layer and maxpool layer 2\n",
    "model2.add(keras.layers.Conv2D(64,(3,3),activation='relu'))\n",
    "model2.add(keras.layers.MaxPool2D(2,2))\n",
    "\n",
    "# Convolutional layer and maxpool layer 3\n",
    "model2.add(keras.layers.Conv2D(128,(3,3),activation='relu'))\n",
    "model2.add(keras.layers.MaxPool2D(2,2))\n",
    "\n",
    "# Convolutional layer and maxpool layer 4\n",
    "model2.add(keras.layers.Conv2D(128,(3,3),activation='relu'))\n",
    "model2.add(keras.layers.MaxPool2D(2,2))\n",
    "\n",
    "# This layer flattens the resulting image array to 1D array\n",
    "model2.add(keras.layers.Flatten())\n",
    "\n",
    "# Hidden layer with 512 neurons and Rectified Linear Unit activation function \n",
    "model2.add(keras.layers.Dense(512,activation='relu'))\n",
    "\n",
    "# Output layer with single neuron which gives 0 for Cat or 1 for Dog \n",
    "#Here we use sigmoid activation function which makes our model output to lie between 0 and 1\n",
    "model2.add(keras.layers.Dense(4,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "train_dataset = datagen.flow_from_directory(\"../BrainMRI/Training\", target_size=(300,300), batch_size = 32,\n",
    "                                          class_mode = 'categorical', color_mode=\"grayscale\")\n",
    "test_dataset  = datagen.flow_from_directory(\"../BrainMRI/Testing\", target_size=(300,300), batch_size = 32,\n",
    "                                          class_mode = 'categorical', color_mode=\"grayscale\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#steps_per_epoch = train_imagesize/batch_size\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "model2.fit(train_dataset, epochs = 15, batch_size=32, validation_data = test_dataset, callbacks = [early_stopping_monitor])\n",
    "\n",
    "end = time.time() \n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions2 = model2.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_model = MobileNet(\n",
    "#     input_shape=(h, w, 3), \n",
    "#     weights='imagenet',\n",
    "#     include_top=False, \n",
    "#     pooling='avg'\n",
    "# )\n",
    "\n",
    "base_model = VGG16(\n",
    "    input_shape=(h, w, 3), \n",
    "    weights='imagenet',\n",
    "    include_top=False, \n",
    "    pooling='max'\n",
    ")\n",
    "\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = False\n",
    "\n",
    "output_class = 4\n",
    "\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    Dropout(rate=0.5),\n",
    "    Dense(output_class, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystop = EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n",
    "                                            patience=2, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.00001)\n",
    "\n",
    "callbacks = [earlystop, learning_rate_reduction]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(datagen.flow(X_train, y_train, batch_size = batch_size), validation_data = (X_test, y_test),\n",
    "                    steps_per_epoch = len(X_train) / batch_size, epochs = epochs, callbacks = EarlyStopping(patience=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
